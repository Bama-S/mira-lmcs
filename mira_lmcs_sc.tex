\documentclass[a4paper,11pt]{lmcs}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{natbib}
\newcommand{\bigseq}{\mathop{\raisebox{0.3ex}{\scalebox{1.5}{$\prod$}}}}
\newcommand{\paralleli}{\mathrel{\|_i}}




% Specify the name of your bibliography file

%\newtheorem{proposition}[theorem]{Proposition}%
%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

%\theoremstyle{thmstyletwo}%
%\newtheorem{example}{Example}%
%\newtheorem{remark}{Remark}%

%\theoremstyle{thmstylethree}%
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}%

\newcommand{\mimamsa}{M\={i}m\={a}\.ms\={a}}
%opening
\title{A M\={i}m\={a}\.{m}s\={a} Inspired Framework for Instruction Sequencing}
\author{}
\address{}
\email{}
\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

In the rapidly evolving field of artificial intelligence, AI agents are increasingly tasked with executing complex sequences of instructions to achieve specified goals. These agents, ranging from robotic systems to large language model (LLM)-based assistants, must interpret, order, and perform actions in a coherent manner to ensure effective and reliable outcomes. However, challenges arise in handling ambiguous, interdependent, or repetitive instructions, where improper sequencing can lead to inefficiencies, errors, or failures. Traditional approaches in task planning and imperative logic often fall short in addressing these issues, particularly in dynamic environments where dependencies between actions and objects evolve over time.

This paper draws inspiration from the ancient Indian philosophical system of \mimamsa, a hermeneutical tradition focused on interpreting Vedic texts through principled methods of ordering and resolving ambiguities in prescriptions. \mimamsa~ offers a rich set of sequencing principles—such as Śrutikrama (direct assertion), Arthakrama (purpose-based ordering), and Pravṛttikrama (iterative procedure)—that ensure uninterrupted and coherent execution. By adapting these principles to computational frameworks, we propose an extended formal system for instruction sequencing in AI agents.

Building upon the foundational work of Srinivasan and Parthasarathi (2021) on imperative logic with action-object pairs, this framework refines the syntax and semantics to explicitly incorporate preconditions, purposes, and dependencies. Key contributions include:
\begin{itemize}
\item An extension of the imperative language to decompose instructions into action-object pairs, enabling precise representation and evaluation.
\item Formalization of three Mīmāṃsā-inspired sequencing methods: direct assertion for temporal ordering, purpose-based sequencing for functional dependencies, and iterative procedures for repetitive tasks.
\item Definitions of object dependency and functional dependency conditions, along with a validity theorem that ensures sequence coherence through state consistency.
\item Deduction rules (Object-Consistent Sequencing and Purpose-Linked Sequencing) for deriving valid sequences, with proofs of soundness and completeness relative to the semantic model.
\item Discussion of implementation via the MIRA AI Agent, leveraging LLMs for practical validation.
\end{itemize}
The remainder of the paper is structured as follows: Section 2 extends the syntax and semantics for action-object imperative logic. Section 3 introduces the sequencing methods. Section 4 details object and functional dependencies, including the validity theorem. Section 5 provides the deduction rules and proofs of soundness and completeness. Section 6 outlines the implementation, followed by conclusions.

\section{Related Work}
Reasoning with actions has been the focus of extensive research across multiple domains, including formal logic, task planning and more recently, large language models. This section presents an overview of the major developments in these areas.
\subsection{Classical Planning and Temoral Logic}
Traditional planning systems, such as STRIPS, model actions as transitions between states \citep{strips}. Each action is described using classical logic formulas that define its preconditions and effects. A search process is employed to navigate from the initial state—characterized by the preconditions—to the goal state—characterized by the desired effects. The resulting path represents a sequence of actions that together form a plan.

Although this method is robust, there are some disadvantages:
\begin{itemize}
 \item Simultaneous actions cannot be represented
 \item Representation of composite actions is difficult
 \item External event representation is not possible
\end{itemize}
To some extent, these challenges have been mitigated by incorporating temporal logic into planning frameworks \citep{allen}. Temporal logic deals with reasoning about time using the operators $\square$ (\textit{always}) and $\Diamond$ (\textit{eventually}), $\bigcirc$ (\textit{next}) and $U$ (\textit{Until}) \citep{huth} In this approach, events are treated as objects, and necessary conditions—such as preconditions—are expressed over temporal intervals. This allows for the construction of non-linear plans and provides the flexibility to represent concurrent actions. However, this method does not handle the decomposition of complex plans into simpler tasks. To overcome this limitation, a hierarchical planning structure is adopted, incorporating temporal reasoning across subtasks \citep{fei}.
Extending the work of Allen, Henry A. Kautz and Peter B. Ladkin, has provided a temporal reasoning system that handles dates, duration and disjointness \citep{kautz}.

Given the general intractability of AI planning, one effective approach is to incorporate domain-specific knowledge. In this direction, knowledge specific to the problem domain is utilized to guide the search process, resulting in a sequence of actions that constitute a valid plan \citep{Bacchus2000}. This domain knowledge is expressed using Linear Temporal Logic (LTL), along with the GOAL modality. This method offers several advantages, including modularity, a declarative specification of the planning problem, and the transformation of intractable problems into solvable ones. In another work, the goal is represented as a sequence of states rather than a single final state \citep{Bacchus1996}. Metric Interval Temporal Logic (MITL) is employed to capture various types of goals, including those with temporal deadlines, quantified goals (both universal and existential), as well as safety and maintenance goals.

Recent advancements in automated planning have highlighted various approaches to explanation-based reasoning \citep{expai}. These approaches encompass algorithmic methods, model-based techniques, inference reconciliation, model reconciliation, and plan-based explanations.
\subsection{Hierarchial Planning}
Hierarchical planning extends classical planning by introducing a structured task hierarchy consisting of two main types of tasks: **primitive tasks** (directly executable actions) and **compound tasks** (or abstract tasks). Unlike classical planning, which focuses on achieving a fixed goal state, hierarchical planning aims to accomplish a set of interrelated tasks \cite{hplan2}. The most common framework for this approach is **Hierarchical Task Network (HTN) planning**, which employs rule-based decomposition methods to break down compound tasks into smaller task networks. This allows the explicit representation of procedural knowledge and domain-specific constraints \cite{htn1}.

Hierarchical planning has proven effective in intelligent user assistance scenarios—for instance, guiding the assembly of a complex home theater system with components such as a Blu-ray player, amplifier, and television \cite{hplan1}. In such a case, the overarching goal might begin as a compound task like *connect(Blu-ray, TV)*. This abstract task is then refined through decomposition rules that specify how the devices should be connected—either directly using primitive *plugIn* actions or indirectly through an intermediate device (*?din*). By embedding constraints such as signal flow within the hierarchy, the planner efficiently narrows the search space and produces valid, step-by-step instructional guidance.
\subsection{Plan Recognition and Goal Inference}
In the study of activity, plan, and goal recognition, the authors have examined these as a unified problem that reflects the natural way humans perceive such processes \citep{goal_act_plan}. From a computational perspective, four main approaches have been explored: logic-based methods, which are structured and rigid; classical machine learning techniques, which employ statistical models to manage uncertainty and noisy data; deep learning approaches, which automatically extract features from sensor data and are particularly effective for activity recognition; and brain-inspired models, which address ambiguity in real-world contexts. The review highlights the need for a unified framework that integrates the strengths of all these approaches.

In the paper “Goal and Plan Recognition Design for Plan Libraries,” the authors extend the traditional Goal Recognition Design (GRD), originally defined for STRIPS domains, to one that incorporates plan libraries, enabling the representation of hierarchical structures and complex agent behaviors \citep{plan_library}. They define two related problems: Goal Recognition Design for Plan Libraries (GRD-PL), which focuses on identifying what goal an agent is pursuing, and Plan Recognition Design (PRD), which focuses on how the goal is achieved. Two key metrics are introduced here namely, Worst-Case Distinctiveness (\textit{wcd}), measuring the maximum number of observations needed to unambiguously determine the goal, and Worst-Case Plan Distinctiveness (\textit{wcpd}), for determining the specific plan. The study demonstrates that wcd serves as a theoretical lower bound for wcpd, offering domain designers practical tools to quantify and minimize ambiguity, thereby enhancing the accuracy and efficiency of real-time plan and goal recognition systems.

\subsection*{Dependency and Semantic Relations}
Several studies have focused on identifying dependency relations among words in natural language sentences. In Semantic Role Labeling (SRL), the verb is treated as the root or predicate, and the relationships of other words to this predicate are analyzed \citep{srl}. For instance, in the sentence “Chrysler plans new investment in Latin America”, the verb plans serves as the predicate, semantically linked to the agent (Chrysler) and the patient (investment).

In dependency parsing, each word in a sentence is connected to another word, except for one — typically the verb, which functions as the root node. For example, in the sentence “A man sleeps”, sleeps is the root, man depends on sleeps, and a depends on man \citep{srl_survey}. Dependency structures adhere to certain axioms, such as the single-head property (each element depends on only one head) and the projective property, which ensures that no two dependency edges intersect. However, the latter is frequently violated in languages with flexible word order. These word-to-word dependencies offer valuable insight into the underlying semantic relationships within a text.
\subsection{BDI Model and Practical Reasoning}
Analogous to how humans select actions based on their goals, the Belief–Desire–Intention (BDI) model endows an intelligent agent with goal-oriented reasoning by representing goals as *desires* and actionable commitments as *intentions*, guided by the agent’s current *beliefs* \citep{bdi}, \citep{bdi_reasoning}. For instance, if a robot’s goal is to deliver a package, it might form a plan and commit to executing it—such as “take hallway A to room 10.” However, if it discovers that the hallway is blocked (a new belief), it will revise its intention and replan accordingly. This framework enables the agent to behave rationally by continuously updating its knowledge, selecting actions aligned with its goals, and adapting dynamically to environmental changes.

\subsection{Normative Systems and Philosophical Foundations}
Normative logic in both Western and Indian philosophical traditions shares a common view on how rules and obligations guide rational action \citep{sanyal}. Deontic logic formalizes such norms through concepts of obligations and prohibitions, offering a useful framework for reasoning in multi-agent systems. Similarly, the Indian philosophical system of \mimamsa presents a sophisticated hermeneutical framework for interpreting texts, providing well-developed principles to distinguish between primary and auxiliary duties as well as exceptions \citep{davis}.

\subsection{Imperative Logic and Action Representation}
Imperatives differ from declarative statements in that they cannot be evaluated as \textit{True} or \textit{False}, which limits the applicability of classical logic in reasoning about them. To address this, several studies have explored translating imperatives into propositions and then applying classical logic rules. However, such approaches often encounter paradoxes, as highlighted by Ross, revealing fundamental limitations in representing imperatives within standard logical frameworks. A detailed survey of various perspectives on imperative logic, particularly in the context of action representation in AI, has been presented in \citep{survey}.Inspired by the Indian philosophical system of \mimamsa, a three-valued formalism has been proposed to handle imperatives, where each instruction is evaluated as \textit{Satisfaction} ($S$), \textit{Violation} ($V$), or \textit{No intention to achieve the goal} ($N$) \citep{mira}. This framework provides a more expressive representation of the normative and intentional aspects of actions than classical logic. Building on this foundation, the same authors have also extended the formalism to handle the temporal sequencing of instructions, enabling reasoning about ordered action execution \citep{llmmira}.

\subsection{Task Planning with Large Language Models}
Oflate LLM has been seen to be helpful for helping task planning.
 Although LLMs excel at text generation and general reasoning, they struggle with temporal reasoning. A proposed solution involves translating temporal information into a graph structure, enabling LLMs to learn and reason over it more effectively \citep{xiong}. LLMs do not always produce truthful or consistent responses and may sometimes generate hallucinated or incorrect information. To address these issues and better align model outputs with human expectations, InstructGPT was developed using reinforcement learning from human feedback (RLHF) \citep{llm_human}


\subsection*{Positioning of the proposed paper}
The proposed \mimamsa–inspired framework advances this domain by offering a philosophically grounded approach to instruction sequencing across several dimensions, as outlined below:
\begin{itemize}
\item **Philosophical Foundation:** In contrast to purely algorithmic methods, the proposed framework is rooted in the hermeneutical principles of \mimamsa~philosophy, providing systematic techniques for resolving ambiguities and ensuring coherent sequencing.
\item **Action–Object Decomposition:** By explicitly modeling instructions as action–object pairs, the framework enables more precise dependency analysis than traditional representations based solely on atomic actions.
\item **Multiple Sequencing Paradigms:** The formalization of three complementary sequencing strategies—direct assertion, purpose-based sequencing, and iterative procedures—offers flexibility for coordinating different instruction types.
\item **Formal Verification:** The inclusion of deduction rules and completeness proofs ensures formal guarantees of sequence validity, effectively linking philosophical reasoning with computational verification.
\item **Cultural Perspective:** Drawn from Indian philosophical traditions, this work expands the Western-centric theoretical foundations of reasoning systems.
\end{itemize}

 \section{Extension of Syntax and Semantics for Action-Object Imperative Logic}
This section extends the formal syntax and semantics framework of Srinivasan and Parthasarathi (2021) \cite{mira} by refining imperative instructions to explicit action-object pairs.
\subsection{Syntax}
\label{sec:syntax}
The language of imperatives is given by \(\mathcal{L}_i = \langle I, R, P, B \rangle\), where:
\begin{itemize}
  \item \(I = \{ i_1, i_2, \ldots, i_n \}\) is the set of imperatives,
  \item \(R = \{ r_1, r_2, \ldots, r_n \}\) is the set of reasons or Preconditions
  \item \(P = \{ p_1, p_2, \ldots, p_n \}\) is the set of purposes (goals),
  \item \(B = \{ \wedge, \vee, \rightarrow_r, \rightarrow_i, \rightarrow_p \}\) is the set of binary connectives.
\end{itemize}

Here, \(R\) and \(P\) are propositions, following propositional formula syntax. They combine with imperatives \(I\) in several forms to build Imperative Formulas \(\mathcal{F}_i\), specified by Equation \ref{eq:formation}:

\begin{eqnarray}
\label{eq:formation}
\mathcal{F}_i = \{
i \mid i \rightarrow_p p \mid (i \rightarrow_p p_1) \wedge (j \rightarrow_p p_2) \mid (i \rightarrow_p \theta) \oplus (j \rightarrow_p \theta) \mid (\varphi \rightarrow_i \psi) \mid (\tau \rightarrow_r \varphi)
\}
\end{eqnarray}

The fundamental unit of an imperative, denoted \(i\), decomposes into an action and a set of objects. For example, the instruction \emph{``Take a book''} associates the action \emph{``take''} with the object \emph{``book''}.

Formally, this association is a function:
\[
f : I \to A \times \mathcal{P}(O),
\]
where \(I = \{ i_1, i_2, i_3, \ldots, i_n \}\) is a set of instructions,
\(A = \{ a_1, a_2, \ldots, a_k \}\) is a set of actions, and
\(O = \{ o_1, o_2, \ldots, o_m \}\) is a set of objects.

Each instruction \(i_j \in I\) can be represented as:
\begin{eqnarray}
\label{eq:ac_ob}
i_j = (a_j, o_j)
\end{eqnarray}
where \(a_j \in A\), and \(o_j \subseteq O\).

Here, each action can stand alone, or be paired with zero, one, or multiple objects as summarized in Table \ref{tab:ac_ob}.

\begin{table}[h!]
\label{tab:ac_ob}
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Action Type}           & \textbf{Representation}             & \textbf{Example}                \\
\hline
Action with object             & \((a_j, \{ o_k \})\)                & \((\texttt{pick}, \{\texttt{rice}\})\) - \emph{pick rice} \\
\hline
Action with multiple objects   & \((a_j, \{ o_k, o_m \})\)          & \((\texttt{cook}, \{\texttt{rice}, \texttt{pot}\})\) - \emph{cook rice in pot} \\
\hline
Action without object          & \((a_j, \emptyset)\)                & \((\texttt{wait}, \emptyset)\) - \emph{wait} \\
\hline
\end{tabular}
\caption{Instruction representations for actions paired with zero, one, or multiple objects.}
\end{table}


\subsection{Semantics}
The semantics defines how each imperative formula is interpreted over the model, assigning it a satisfaction status based on system states, actions, objects, and goal-directed intentions.
A semantic model \(\mathcal{M}\) is defined as:
\begin{eqnarray}
\label{eq:model}
\mathcal{M} = \langle \mathcal{R}, \mathcal{A}, \mathcal{O}, \mathcal{G}, intention, eval \rangle,
\end{eqnarray}
where
\begin{itemize}
    \item \(\mathcal{R}\) is the set of Preconditions,
    \item \(\mathcal{A}\) is the set of actions,
    \item \(\mathcal{O}\) is the set of objects,
    \item \(\mathcal{G}\) is the set of goals,
    \item \(intention : \mathcal{R} \times \mathcal{G} \to \{ true, false \}\),
    \item \(eval : \mathcal{R} \times (\mathcal{A} \times \mathcal{O}) \to \{ S, V, N \}\).
\end{itemize}

The semantic evaluations for different imperatives are given as follows:

\begin{itemize}
 \item \textbf{Unconditional Imperatives}:
\[
eval(r, (a, o)) =
\begin{cases}
S, & \text{if the action } a \text{ is successfully performed on } o \text{ in } r, \\
V, & \text{otherwise}.
\end{cases}
\]

\item \textbf{Imperative Enjoining Goal}:
\[
eval(r, (a, o) \rightarrow_p g) =
\begin{cases}
S, & \text{if the agent intends } g \text{ and } (a,o) \text{ is satisfied in } r, \\
V, & \text{if the agent intends } g \text{ and } (a,o) \text{ is violated in } r, \\
N, & \text{if there is no intention to achieve goal } g.
\end{cases}
\]

\item \textbf{Imperatives in Sequence}:
\[
eval(s, (a_1, o_1) \rightarrow_i (a_2, o_2)) =
\begin{cases}
S, & \text{if } eval(r, (a_1, o_1)) = S \text{, } eval(s', (a_2, o_2)) = S \text{ and object consistency holds,} \\
V, & \text{if } eval(r, (a_1, o_1)) = V \text{ or } eval(s', (a_2, o_2)) = V.
\end{cases}
\]

\item \textbf{Imperatives in Parallel}:
\[
eval((r_1, (a_1, o_1)) \wedge (r_2, (a_2, o_2))) =
\begin{cases}
S, & \text{if } eval(r_1, (a_1, o_1)) = S, \quad eval(r_2, (a_2, o_2)) = S, \\
& \text{and object consistency does not hold,} \\
V, & \text{if } eval(r_1, (a_1, o_1)) = V \text{ or } eval(r_2, (a_2, o_2)) = V.
\end{cases}
\]

\item \textbf{Imperatives with Choice}:
\[
eval((r_1, (a_1, o_1)) \oplus (r_2, (a_2, o_2))) =
\begin{cases}
S, & \text{if } eval(r_1, (a_1, o_1)) = S \text{ or } eval(r_2, (a_2, o_2)) = S, \\
V, & \text{if } eval(r_1, (a_1, o_1)) = V \text{ and } eval(r_2, (a_2, o_2)) = V.
\end{cases}
\]
\end{itemize}
This formal action-object representation provides a foundation for capturing the ordering and dependency relationships among instructions. The philosophy of \mimamsa\ includes several principled methods for sequencing such instructions to achieve coherent execution. The next section introduces these methods and formally develops three sequencing strategies by extending this representation.

\section{Sequencing Methods}
\label{sec:seq}
According to the Indian philosophical system of \mimamsa, a set of instructions can be sequenced using six distinct ordering principles to ensure coherent and uninterrupted execution. These are: Direct Assertion (\textit{Śrutikrama}), Purpose-Based Sequencing (\textit{Arthakrama}), Order as Given (\textit{P\={a}\d{t}hakrama}), Position-Based Order (\textit{Sth\={a}nakrama}), Principal Activity-Based Order (\textit{Mukhyakrama}), and Iterative Procedure (\textit{Pravri\d{t}\d{t}ikrama}). For more details on the sequencing aspects from the philosophy, the reader may refer to the prior work on temporal ordering of instructions \cite{llm_mira}. Among these, three methods—Direct Assertion, Purpose-Based Sequencing, and Iterative Procedure—are formalized in this paper and discussed in Sections \ref{sec:sruti}, \ref{sec:artha}, and \ref{sec:pravritti}, respectively.


\subsection{Direct Assertion (\'{S}rutikrama)}
\label{sec:sruti}
In this type, instructions are provided in a direct and sequential manner. Following the notation from the work of sequencing methods based on \mimamsa~\cite{llm_mira}, let:
\begin{itemize}
 \item $i_t = (a_t,o_t)$: instruction at the first instant $t$, with action $a_t$ and object(s) $o_t$
\item $i_{t+1} = (a_{t+1},o_{t+1})$: instruction at the next instant $t+1$
 \end{itemize}
Then, Instruction in sequence can be expressed by Equation \ref{eq:sruti}.
\begin{eqnarray}
\label{eq:sruti}
 (a_t o_t) \rightarrow_i (a_{t+1}o_{t+1})
\end{eqnarray}
where $\rightarrow_i$ denotes temporal sequencing of actions on objects. The indication can be read as  ``perform $a_t$ on $o_t$, then perform $a_{t+1}$ on $o_{t+1}$''.

For a sequence of $n$ instructions, the temporal order and precedence can be formally represented using nested left brackets as shown in Equation \ref{eq:sruti_ext}.
\begin{eqnarray}
 \label{eq:sruti_ext}
(\cdots ((a_1 o_1) \rightarrow_i (a_2 o_2)) \rightarrow_i (a_3 o_3) \cdots ) \rightarrow_i (a_n o_n)
\end{eqnarray}

This representation indicates that each instruction must be completed before the next instruction.

For example, consider three statements \textit{``pick rice''}, \textit{``cook rice in pot''}, \textit{``add rice to dish''}. These can be represented as:
\begin{eqnarray}
 (((pick \{rice\}) \rightarrow_i (cook \{rice,
 pot\})) \rightarrow_i (add \{rice,dish\}))
\end{eqnarray}
Here, objects are progressively updated across instructions. For instance, “rice” becomes “cooked rice” after executing the instruction “cook rice.” This transformation indicates that the instructions are linked through evolving object states, a relationship known as \textbf{object dependency}.

This type of representation serves two major purposes.

\begin{enumerate}
 \item It indicates the temporal order of the actions.
 \item The dependencies of objects the across each step is enforced.
\end{enumerate}
\subsection{Sequencing based on purpose}
\label{sec:artha}
In this type, each instruction is of the form $(\tau \rightarrow_r (i \rightarrow_p p))$ \cite{llm_mira}, indicating there is a precondition ($\tau$) for the instruction ($i$) to take place, inorder to achieve the goal ($p$). Here, $\rightarrow_r$ and $\rightarrow_p$ denote ``because of reason (indicating precondition)'' and ``inorder to achieve  goal'', respectively.

This representation can be extended to a series of instructions as given by Equation \ref{eq:artha_ext}.
\begin{eqnarray}
 \label{eq:artha_ext}
 (r_1 \rightarrow_r (i_1 \rightarrow_p p_1)), (r_2 \rightarrow_r (i_2 \rightarrow_p p_2), ..., (r_n \rightarrow_r (i_n \rightarrow_p p_n))
\end{eqnarray}

If the purpose $p_k$ of instruction $i_k$ becomes the precondition $r_{k+1}$ for the next instruction $i_{k+1}$, then $i_k$ precedes $i_{k+1}$, because $r_{k+1} = p_k$. This relation signifies that the second insruction ($i_{k+1}$) depends on the first ($i_k$) and is referred to as \textbf{functional dependency} and has already been used in task analysis for special education \cite{ta}.

Extending this further into the representation  of $i_j$ as ($a_j,o_j$) pair, Equation \ref{eq:artha_ext} can be formalized as shown in Equation \ref{eq:ao_artha}.
\begin{eqnarray}
 \label{eq:ao_artha}
\forall j \in \{1,...,n-1\}: r_j \rightarrow_r ((a_j,o_j) \rightarrow_p p_j), r_{j+1} = p_j
\end{eqnarray}

\subsection{Sequential and Parallel Execution Methods for Repetitive Tasks}
\label{sec:pravritti}
In some tasks, it is necessary to repeat the same action multiple times across different items. Two common approaches to sequence such repetitive actions have been identified in previous work with LLMs \cite{llm_mira}, reiterated here for clarity.

Consider the task of a teacher grading answer scripts from 20 students, each answer script containing 5 questions. In the \textbf{Sequential Completion Method}, the teacher grades all five questions of the first student's script before moving on to completely grade the second student’s script, continuing this process sequentially for all students. Alternatively, the \textbf{Step-by-Step Parallel Method}, also known as the \textbf{Iterative Procedure}, involves the teacher grading the first question across all 20 scripts before proceeding to grade the second question for all scripts, and so forth.


\subsubsection{Sequential Completion Method}
In this method, the full sequence is performed on one object and the same sequence is repeated for all other objects.

Formally, it can be represented as follows:

Let there be $n$ actions $A = \{a_1,a_2,...,a_n\}$ and $T$ objects for each action, $O_k = \{o_{k1},o_{k2},...,o_{kT}\}$ for $1\leq k \leq n$.

For each object $o_j (1 \leq j \leq T)$, the sequence is given by Equation \ref{eq:seq_single}.
\begin{eqnarray}
 \label{eq:seq_single}
 (a_1o_{1j} \rightarrow_i a_2o_{2j} \rightarrow_i... \rightarrow_i a_no_{nj})
\end{eqnarray}

This is repeated for all $j$ as shown below.


\begin{eqnarray}
\label{eq:seq_m}
\bigseq_{j=1}^T (a_1 o_{1j} \rightarrow_i \cdots \rightarrow_i a_n o_{nj})
\end{eqnarray}


Equation \ref{eq:seq_m} can be interpreted as:
\begin{itemize}
 \item For each object $j$, all actions are performed in sequence before moving to the next object.
 \item The objects involved in sequence are $(o_{1j},o_{2j},...o_{nj})$ for $j$.
\end{itemize}

\subsubsection{Step-by-Step Parallel Method (Iterative Procedure)}
The step-by-step parallel method can be formalized using a parallel composition connective \(\parallel_i\), which groups actions performed independently on different objects without enforcing temporal sequencing or object dependency among them.

Formally, this method is represented as follows:
\begin{eqnarray}
\label{eq:step_parallel_formal}
\Bigl(
(a_1 o_{11} \parallel_i a_1 o_{12} \parallel_i \cdots \parallel_i a_1 o_{1T})
\rightarrow_i \\ \nonumber
(a_2 o_{21} \parallel_i a_2 o_{22} \parallel_i \cdots \parallel_i a_2 o_{2T})
\rightarrow_i \cdots \rightarrow_i \\ \nonumber
(a_n o_{n1} \parallel_i a_n o_{n2} \parallel_i \cdots \parallel_i a_n o_{nT})
\Bigr).
\end{eqnarray}

Here:
\begin{itemize}
  \item \(\parallel_i\) groups the same action \(a_k\) applied to objects \(o_{k1}, \ldots, o_{kT}\) in parallel, without a strict order or dependency between object-specific actions.
  \item \(\rightarrow_i\) imposes a temporal ordering between these groups, requiring all actions in a given group to complete before the next group begins.
\end{itemize}

In this method, the first action is performed on all objects, followed by second action and so on. Same action is grouped and distributed across objects before moving to the next action.

In both the Sequential Completion and Step-by-Step Parallel Methods, object dependency is preserved in accordance with the principle of direct assertion (śrutikrama). Specifically, within the sequential composition $\rightarrow_i$, each instruction group or action sequence enforces the temporal order and dependency relations established by direct assertion, ensuring coherent and consistent execution even when tasks are performed repetitively over multiple objects.

Using these sequencing mechanisms, validity can be logically determined through object dependency and consistency across subsequent instructions, as detailed in the following section.
\section{Object Dependency and Functional Dependency in Instruction Sequencing}

The validity of an instruction sequence relies on two main conditions: \textbf{object dependency} and \textbf{functional dependency} across instructions. These ensure that the instruction sequence respects the logical dependencies and state transformations of objects involved.

\subsection{Object Dependency Condition}
\begin{definition}
\textbf{Object Dependency Condition} \\
A sequence of instructions \( I = \{i_1, i_2, \ldots, i_n\} \), where each \( i_j = (a_j, O_j) \), exhibits valid object dependency if for every pair of consecutive instructions \( (i_j, i_{j+1}) \), there exists at least one object \( o^* \) such that:
\[
o^* \in O_j \cap O_{j+1}.
\]
This signifies that the two instructions share at least one object, establishing a valid dependency consistent with direct assertion (śrutikrama).
\end{definition}

\subsection{Functional Dependency Condition}
\begin{definition}
\textbf{Functional Dependency Condition} \\
For instructions \( i_j = (a_j, O_j) \) and \( i_{j+1} = (a_{j+1}, O_{j+1}) \) with shared objects \( o^* \in O_j \cap O_{j+1} \), the sequence maintains functional dependency if:
\[
s_j(o^*) = s_{j+1}^{\mathrm{req}}(o^*).
\]
Here:
\begin{itemize}
  \item \( s_j(o^*) \) is the state of object \( o^* \) immediately after executing instruction \( i_j \),
  \item \( s_{j+1}^{\mathrm{req}}(o^*) \) is the required state of \( o^* \) to start executing \( i_{j+1} \).
\end{itemize}
This relation captures the classical notion of functional dependency, where the post-state of an object after one instruction determines the input state required for the next.
\end{definition}

\subsection{Validity Theorem for Sequencing}
\begin{theorem}
\label{th:validity}
\textbf{Validity of Instruction Sequence with Object and Functional Dependencies} \\
Let \( I = \{i_1, i_2, \ldots, i_n\} \) be a sequence of instructions with \( i_j = (a_j, O_j) \). The sequence is valid if:
\[
\forall j \in \{1, \ldots, n-1\}, \quad \text{if} \quad D(i_j, i_{j+1}) = \text{True},
\]
then:
\[
O_j \cap O_{j+1} \neq \emptyset \quad \text{and} \quad
\forall o^* \in O_j \cap O_{j+1}, \quad s_j(o^*) = s_{j+1}^{\mathrm{req}}(o^*),
\]
where \( D(i_j, i_{j+1}) \) expresses a dependency between \( i_j \) and \( i_{j+1} \).
\end{theorem}
\begin{proof}
We prove the theorem by induction on the instruction sequence length, focusing on maintenance of functional dependency (state consistency) between consecutive instructions.

\textbf{Base Case:}

Consider the first instruction \( i_1 = (a_1, O_1) \):
\begin{itemize}
    \item Each object \( o \in O_1 \) is initially in state \( s_1^{\mathrm{init}}(o) \).
    \item There are no preceding instructions, so no dependencies are checked.
    \item Instruction \( i_1 \) is executable as long as its required preconditions on object states are satisfied by the initial states.
\end{itemize}

\textbf{Inductive Step:}

Assume that for all instructions up to step \(j\), the following holds: For every pair \((i_k, i_{k+1})\) with \(1 \leq k \leq j-1\),
\[
O_k \cap O_{k+1} \neq \emptyset \quad \text{and} \quad
\forall o^* \in O_k \cap O_{k+1},\ s_k(o^*) = s_{k+1}^{\mathrm{req}}(o^*)
\]
That is, both object dependency and functional dependency are satisfied for all previous pairs in the sequence.


Now consider the next instruction \( i_{j+1} = (a_{j+1}, O_{j+1}) \):
\begin{itemize}
    \item \textbf{Dependency Check:} If \( \exists o^* \in O_j \cap O_{j+1} \), then \( i_{j+1} \) depends on \( i_j \) through object \( o^* \).
    \item \textbf{Functional Dependency Check:} The state of \( o^* \) after executing \( i_j \), denoted \( s_j(o^*) \), must match the required state for \( i_{j+1} \), denoted \( s_{j+1}^{\mathrm{req}}(o^*) \):
    \[
    s_j(o^*) = s_{j+1}^{\mathrm{req}}(o^*).
    \]
\end{itemize}

This ensures that the functional dependency condition is preserved for \( (i_j, i_{j+1}) \), allowing \( i_{j+1} \) to be validly executed. By the principle of induction, the functional dependency holds for all pairs of instructions in the sequence, thereby establishing validity.
\end{proof}

This theorem can be formalized as follows:

\[
\forall j \in \{1, \ldots, n-1\},\
\text{if}\ D(i_j, i_{j+1}) = \text{True}
\implies
\left( O_j \cap O_{j+1} \neq \emptyset\
\ \text{and}\
\forall o^* \in O_j \cap O_{j+1},\ s_j(o^*) = s_{j+1}^{\mathrm{req}}(o^*) \right)
\]

where $D(i_j, i_{j+1})$ indicates a dependency from $i_j$ to $i_{j+1}$.


\subsubsection{Corollary}
A sequence is invalid if there exists a pair \( (i_j, i_{j+1}) \) such that:
\begin{itemize}
  \item \( O_j \cap O_{j+1} = \emptyset \), indicating no common object and thus no dependency.
  \item Or, there exists an object \( o^* \in O_j \cap O_{j+1} \) for which:
    \[
    s_j(o^*) \neq s_{j+1}^{\mathrm{req}}(o^*),
    \]
    violating the functional dependency condition.
\end{itemize}
\subsection{Deduction Rules for Sequencing}

Extending the original deduction rules from MIRA \cite{mira}, this section provides a representation in terms of <\textit{action,object}> pair towards the sequencing methods of direct assertion \ref{sec:srutikrama} and purpose based approach \ref{sec:arthakrama}. Among the deduction rules, only the rule conditional enjoining action $cni$ with $X = \phi$, $Y = \psi$ and $w = i$ is applicable, which reflects the sequencing according to direct assertion method that includes object dependency condition. Additionally, the deduction rule of purpose based sequencing method is also included.


\paragraph{Object-Consistent Sequencing Rule (OCS)}

Assume $i_1$ leads to $i_2$ and there is at least one object common to both instructions. The deduction rule is:

\[
\frac{
    [i_1] \quad \cdots \quad i_2 \qquad O_1 \cap O_2 \neq \emptyset O_1 \cap O_{1} \neq \emptyset \quad \text{and} \quad
\forall o^* \in O_1 \cap O_2
}{
    i_1 \rightarrow_i i_2
} \;\texttt{OCS}
\]

\emph{Explanation:}
This rule states that the sequential composition $i_1 \rightarrow_i i_2$ is derivable if $i_1$ leads to $i_2$ and the two instructions share at least one object. This ensures that sequencing is only permitted when there is object overlap, reflecting the principle of object dependency.

\paragraph{Purpose-Linked Sequencing Rule (PLS)}

Let $i_k$ and $i_{k+1}$ be instructions with preconditions $r_k, r_{k+1}$ and purposes $p_k, p_{k+1}$.

\[
\frac{
  \vdash (r_k \rightarrow_r (i_k \rightarrow_p p_k)) \quad
  \vdash (r_{k+1} \rightarrow_r (i_{k+1} \rightarrow_p p_{k+1})) \quad
  \text{Functional dependency:}\; p_k = r_{k+1}
}{
  \vdash (r_k \rightarrow_r (i_k \rightarrow_p p_k)) \rightarrow (r_{k+1} \rightarrow_r (i_{k+1} \rightarrow_p p_{k+1}))
}PLS
\]

This rule derives a sequenced instruction chain when both components are derivable and the purpose of the first instruction provides the precondition for the second (functional dependency). This implements purpose-based ordering in a set of given instructions.

These rules ensure that instruction sequencing is logically justified only when the relevant object and functional dependencies are maintained. They form the basis for the forthcoming proofs of soundness and completeness, which demonstrate the alignment of proof theory and semantic interpretation in this system.

\section{Soundness and Completeness of Deduction Rules}

In this section, we establish the soundness and completeness of the deduction rules (OCS and PLS) with respect to the semantic model and the Validity Theorem (Theorem 1). Soundness ensures that if a sequence of instructions is derivable using the rules, then it satisfies the semantic validity conditions (both object dependency and functional dependency). Completeness ensures the converse: if a sequence satisfies the semantic validity conditions, then it is derivable using the rules.

We consider sequences of instructions \( I = \{i_1, i_2, \dots, i_n\} \), where each \( i_j = (a_j, O_j) \), and validity is defined per Theorem 1. The semantic model \( M = \langle \mathcal{R}, A, O, G, \textit{intention}, \textit{eval} \rangle \) interprets these sequences, with satisfaction statuses S (satisfied), V (violated), or N (neutral). Derivability (\( \vdash \)) refers to proofs using OCS and PLS.

\subsection{Soundness}

\textbf{Theorem 2 (Soundness).} If a sequence \( I \) is derivable (\( \vdash I \)) using OCS and PLS, then \( I \) is semantically valid in \( M \) (i.e., it satisfies Theorem 1: for all dependent consecutive pairs \( (i_j, i_{j+1}) \), \( O_j \cap O_{j+1} \neq \emptyset \) and \( \forall o^* \in O_j \cap O_{j+1} \), \( r_j(o^*) = r_{j+1}^{\text{req}}(o^*) \), and \( \textit{eval}(r, I) = S \) for some initial precondition \( r \in \mathcal{R} \)).

\textbf{Proof.} We proceed by induction on the length of the derivation.

\textbf{Base Case:} For a single instruction \( i_1 = (a_1, O_1) \), derivability is trivial (no rules applied). Semantic validity holds vacuously (no pairs). By the semantics, \( \textit{eval}(r, (a_1, O_1)) = S \) if \( a_1 \) is performed on objects in \( O_1 \) under precondition \( r \), assuming initial preconditions match requirements.

\textbf{Inductive Step:} Assume soundness holds for derivations of length up to \( k \). Consider a derivation of length \( k+1 \). Since validity requires both object and functional dependencies, derivations involve applications of both OCS and PLS for sequences with such dependencies. The last rule applied could be OCS or PLS, but the full derivation combines them to capture both conditions.

- \textbf{Case OCS (Object Dependency):} The rule derives \( i_1 \rightarrow_i i_2 \) from premises \( [i_1] \dots i_2 \), with \( O_1 \cap O_2 \neq \emptyset \) and object consistency. By inductive hypothesis, the premises are semantically valid (each sub-sequence evaluates to S). Semantics for imperatives in sequence (Section 2.2) yield \( \textit{eval}(r, (a_1, o_1) \rightarrow_i (a_2, o_2)) = S \) if both sub-evaluations are S and object consistency holds. This satisfies the object dependency part of Theorem 1 for the pair. Functional dependency, if required, is preserved through concurrent or prior applications of PLS in the derivation.

- \textbf{Case PLS (Functional Dependency):} The rule derives \( (r_k \rightarrow_r (i_k \rightarrow_p p_k)) \rightarrow (r_{k+1} \rightarrow_r (i_{k+1} \rightarrow_p p_{k+1})) \) from premises with functional dependency \( p_k = r_{k+1} \). By inductive hypothesis, premises are valid. Semantics for purpose-enjoined imperatives ensure \( \textit{eval}(r, (a_k, o_k) \rightarrow_p g) = S \) only if intention holds and the action satisfies the goal. Specifically, in the context of functional dependency: (i) \( (r_k \rightarrow_r (i_k \rightarrow_p p_k)) \) evaluates to S if the intention of the goal \( p_k \) is true and the action \( i_k \) is performed with precondition \( r_k \) true; (ii) after execution, the intention of goal \( p_k \) becomes reality (i.e., the evaluation from step (i) turns to a true value, serving as the precondition for the next step \( r_{k+1} \)); (iii) the next \( (r_{k+1} \rightarrow_r (i_{k+1} \rightarrow_p p_{k+1})) \) then becomes S when the intention of goal \( p_{k+1} \) is true and action \( i_{k+1} \) is performed with precondition \( r_{k+1} \). The linkage \( p_k = r_{k+1} \) enforces functional dependency (post-precondition of \( i_k \) provides the precondition for \( i_{k+1} \)), yielding overall S. Object dependency, if required, is enforced through concurrent or prior OCS applications in the full derivation (e.g., ensuring shared objects with consistent preconditions), satisfying both parts of Theorem 1.

Derivations combine OCS and PLS as needed (e.g., OCS for object overlap and PLS for purpose-precondition chaining in mixed sequences), ensuring both dependencies are captured and leading to overall semantic validity by induction.

\subsection{Completeness}

\textbf{Theorem 3 (Completeness).} If a sequence \( I \) is semantically valid in \( M \) (i.e., satisfies Theorem 1 and \( \textit{eval}(r, I) = S \) for some \( r \in \mathcal{R} \)), then \( I \) is derivable (\( \vdash I \)) using OCS and PLS.

\textbf{Proof.} Again, by induction on the sequence length \( n \).

\textbf{Base Case:} For \( n=1 \), \( i_1 \) is valid if \( \textit{eval}(r, (a_1, O_1)) = S \). No rules needed; derivability is trivial.

\textbf{Inductive Step:} Assume completeness for sequences up to length \( n-1 \). For length \( n \), since \( I \) is valid, all consecutive pairs satisfy both object and functional dependencies per Theorem 1.

The sub-sequence \( \{i_1, \dots, i_{n-1}\} \) is valid by assumption, so derivable by inductive hypothesis. To extend to the full sequence, apply both OCS and PLS as required by the dependencies:

- Apply OCS for object dependency (pairs share objects \( O_j \cap O_{j+1} \neq \emptyset \) and preconditions match), deriving temporal sequencing \( i_{n-1} \rightarrow_i i_n \).

- Apply PLS for functional dependency (pairs link via \( p_j = r_{j+1} \)), deriving purpose-chained sequencing, where the semantic evaluation to S follows the steps: (i) intention of \( p_{n-1} \) true and action performed under \( r_{n-1} \); (ii) post-execution realization of \( p_{n-1} \) as true, becoming \( r_n \); (iii) subsequent evaluation to S for the next imperative under \( r_n \) with intention of \( p_n \) true.

Since Theorem 1 requires both dependencies for validity, apply both rules for each relevant pair: OCS to enforce object overlap and precondition consistency, and PLS to enforce purpose-precondition linkage. For mixed sequences, decompose into sub-sequences, derive them using the appropriate rule(s), then combine. Semantic validity ensures both conditions align with the premises of OCS and PLS, so the full derivation exists by combining the rules.

By induction, all semantically valid sequences are derivable.

These proofs align the proof theory (deduction rules) with the semantics, ensuring the framework's logical consistency for instruction sequencing.



\section{Implementation}
The proposed framework is computationally instantiated through the MIRA AI Agent, a system leveraging Large Language Models (e.g., Groq, Gemini) for instruction generation and sequence validation. This agent, detailed in future work, demonstrates the practical feasibility of our semantic model, with real-time deployment as a web application. Current efforts focus on formal verification, with implementation specifics to be elaborated in a forthcoming paper.

\bibliographystyle{plainnat} % or any style you prefer, e.g., unsrtnat for numerical order
\bibliography{mira_ref}

\end{document}
